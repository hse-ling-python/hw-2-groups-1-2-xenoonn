{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in /Users/ico/anaconda3/lib/python3.7/site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in /Users/ico/anaconda3/lib/python3.7/site-packages (from pymystem3) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/ico/anaconda3/lib/python3.7/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/ico/anaconda3/lib/python3.7/site-packages (from requests->pymystem3) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ico/anaconda3/lib/python3.7/site-packages (from requests->pymystem3) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ico/anaconda3/lib/python3.7/site-packages (from requests->pymystem3) (1.24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in /Users/ico/anaconda3/lib/python3.7/site-packages (0.8)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /Users/ico/anaconda3/lib/python3.7/site-packages (from pymorphy2) (2.4.393442.3710985)\n",
      "Requirement already satisfied: dawg-python>=0.7 in /Users/ico/anaconda3/lib/python3.7/site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /Users/ico/anaconda3/lib/python3.7/site-packages (from pymorphy2) (0.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opening():\n",
    "    with open('groza.txt', encoding = 'utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "text = opening()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время работы:  1.13230299949646 сек.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def parsing(text):\n",
    "    start = time.time()\n",
    "    ana = m.analyze(text)\n",
    "    end = time.time()\n",
    "    print('Время работы: ', end - start, 'сек.')\n",
    "    return ana\n",
    "ana = parsing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def write(ana):\n",
    "    with open('new.json','w',encoding = 'utf-8') as d:\n",
    "        json_ana = json.dump(ana, d, ensure_ascii=False)\n",
    "    return json_ana\n",
    "json_ana = write(ana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/ico/anaconda3/lib/python3.7/site-packages (3.4.4)\n",
      "Requirement already satisfied: six in /Users/ico/anaconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ico/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def token(text):\n",
    "    token_text = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
    "    return token_text\n",
    "token_text = token(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время работы:  2.7119250297546387 сек.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def pymorphh(token_text):\n",
    "    data =  []\n",
    "    start = time.time()\n",
    "    for word in token_text:\n",
    "        data.append(morph.parse(word))\n",
    "    end = time.time()\n",
    "    print('Время работы: ', end - start, 'сек.')\n",
    "    return data\n",
    "data = pymorphh(token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmas(data):\n",
    "    \n",
    "    kok = list(data)\n",
    "    k_str = ' '.join(str(x) for x in kok)\n",
    "    ana_2 = k_str.split(', ')\n",
    "    return ana_2\n",
    "ana_2 = lemmas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def file_2(ana_2):\n",
    "    with open('new_2.json','w',encoding = 'utf-8') as d:\n",
    "        json_ana = json.dump(ana_2, d, ensure_ascii=False)\n",
    "    return json_ana\n",
    "json_ana = file_2(ana_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Часть речи -  NOUN доля в тексте -  21 %\n",
      "Часть речи -  ADJF доля в тексте -  7 %\n",
      "Часть речи -  PREP доля в тексте -  8 %\n",
      "Часть речи -  NUMR доля в тексте -  0 %\n",
      "Часть речи -  CONJ доля в тексте -  14 %\n",
      "Часть речи -  ADVB доля в тексте -  6 %\n",
      "Часть речи -  VERB доля в тексте -  15 %\n",
      "Часть речи -  INFN доля в тексте -  3 %\n",
      "Часть речи -  ADJS доля в тексте -  1 %\n",
      "Часть речи -  PRCL доля в тексте -  10 %\n",
      "Часть речи -  NPRO доля в тексте -  12 %\n",
      "Часть речи -  GRND доля в тексте -  1 %\n",
      "Часть речи -  PRTS доля в тексте -  0 %\n",
      "Часть речи -  INTJ доля в тексте -  1 %\n",
      "Часть речи -  PRED доля в тексте -  1 %\n",
      "Часть речи -  COMP доля в тексте -  1 %\n",
      "Часть речи -  PRTF доля в тексте -  0 %\n",
      "Часть речи -  None доля в тексте -  0 %\n"
     ]
    }
   ],
   "source": [
    "def counting(token_text):\n",
    "    d = {}\n",
    "    verbs = []\n",
    "    adverbs = []\n",
    "    len_text = len(token_text)\n",
    "    for i in range(len(token_text)):\n",
    "        w = morph.parse(token_text[i])[0]\n",
    "        if w.tag.POS in d:\n",
    "            d[w.tag.POS] += 1\n",
    "        else:\n",
    "            d[w.tag.POS] = 1\n",
    "        if w.tag.POS == 'VERB':\n",
    "            verbs.append(w.normal_form)\n",
    "        elif w.tag.POS == 'ADVB':\n",
    "            adverbs.append(w.normal_form)\n",
    "            verbs.append(w.normal_form)\n",
    "    for key in d:\n",
    "        print('Часть речи - ',key, 'доля в тексте - ', round(d[key] / len_text * 100),'%')\n",
    "counting(token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-20 частотных глаголов:\n",
      "быть\n",
      "знать\n",
      "хотеть\n",
      "говорить\n",
      "мочь\n",
      "видеть\n",
      "пойти\n",
      "любить\n",
      "уходить\n",
      "стать\n",
      "бояться\n",
      "входить\n",
      "идти\n",
      "сказать\n",
      "делать\n",
      "прийти\n",
      "думать\n",
      "смотреть\n",
      "сделать\n",
      "гулять\n"
     ]
    }
   ],
   "source": [
    "def popular_verbs(token_text):\n",
    "    d = {}\n",
    "    verbs = []\n",
    "    len_text = len(token_text)\n",
    "    for i in range(len(token_text)):\n",
    "        w = morph.parse(token_text[i])[0]\n",
    "        if w.tag.POS == 'VERB':\n",
    "            verbs.append(w.normal_form)\n",
    "    top20 = Counter(verbs).most_common(20)\n",
    "    print('Топ-20 частотных глаголов:')\n",
    "    for k in top20:\n",
    "        print(k[0])\n",
    "popular_verbs(token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-20 частотных глаголов:\n",
      "уж\n",
      "теперь\n",
      "здесь\n",
      "точно\n",
      "там\n",
      "тут\n",
      "где\n",
      "домой\n",
      "зачем\n",
      "хорошо\n",
      "тоже\n",
      "потом\n",
      "очень\n",
      "несколько\n",
      "мало\n",
      "никогда\n",
      "сюда\n",
      "тогда\n",
      "потому\n",
      "совсем\n"
     ]
    }
   ],
   "source": [
    "def popular_adverbs(token_text):\n",
    "    d = {}\n",
    "    adverbs = []\n",
    "    len_text = len(token_text)\n",
    "    for i in range(len(token_text)):\n",
    "        w = morph.parse(token_text[i])[0]\n",
    "        if w.tag.POS == 'ADVB':\n",
    "            adverbs.append(w.normal_form)\n",
    "    top20 = Counter(adverbs).most_common(20)\n",
    "    print('Топ-20 частотных глаголов:')\n",
    "    for k in top20:\n",
    "        print(k[0])\n",
    "popular_adverbs(token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
